---
layout: post
title: Week 8
---

Week 8: July 20 to July 24

After running some tests on the depth camera intel real sense d 435 I found out that the results object is not that different.
It is basically the streamer of the camera, the prediction label of the framed image with the accuracy and the distance that the code calculated.
This calculation is done with the idea of the bounding boxes that I explained in a previous post.
However, it is preprogrammed into the edgeiq library from AlwaysAI on the RealSense_objectDetector program.
I needed to modify the code to output the useful informationâ€™s on terminal in order to manipulate them.
Now I print on terminal object + distance.
With a condition function I filtered by whenever the object is not classified as a person.
Then I ran a set of tests to see the precision of the camera.
In different setups I asked people to walk toward the camera and annotated what the result of the distance outputted by the code was.
With a measuring tape I checked the precision.
It turned out to be very precise. More accurate results can be found in the final report.
With that in mind now we are brain storming how to make this into useful information.
Professor Namboodiri suggested using beeps, I wanted to give a try for a speaker.
I believe that the speaker might be able to deliver more information, but again it might be too much information, so that is the decision for next week.



